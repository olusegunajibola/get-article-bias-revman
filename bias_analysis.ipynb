{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-25T00:33:21.883163Z",
     "start_time": "2025-03-25T00:33:21.878361Z"
    }
   },
   "source": "GROQ_API_KEY = \"ABCD\"",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T00:33:34.129906Z",
     "start_time": "2025-03-25T00:33:33.280408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from groq import Groq\n",
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Initialize Groq API Client\n",
    "client = Groq(api_key=os.getenv('GROQ_API_KEY'))"
   ],
   "id": "c3ac5e7a664c5583",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T00:33:57.736988Z",
     "start_time": "2025-03-25T00:33:57.730641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a given PDF file.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\\n\".join([page.get_text(\"text\") for page in doc])\n",
    "    return text"
   ],
   "id": "b0aa7fc785720a82",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T00:49:51.223173Z",
     "start_time": "2025-03-25T00:49:51.185893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_text(text, max_tokens=2000):\n",
    "    \"\"\"Splits text into smaller chunks to fit within token limits.\"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    chunk = []\n",
    "\n",
    "    for word in words:\n",
    "        chunk.append(word)\n",
    "        if len(chunk) >= max_tokens:  # Approximate token count\n",
    "            chunks.append(\" \".join(chunk))\n",
    "            chunk = []\n",
    "\n",
    "    if chunk:\n",
    "        chunks.append(\" \".join(chunk))\n",
    "\n",
    "    return chunks"
   ],
   "id": "acfb83e86c9ee4be",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T00:57:59.414699Z",
     "start_time": "2025-03-25T00:57:59.406206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def summarize_text(text):\n",
    "    \"\"\"Summarize the extracted text before classification to reduce token size.\"\"\"\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI that summarizes long text efficiently.\"},\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f\"Summarize this text concisely while keeping key bias-related information:\\n\\n{text}\"}\n",
    "        ],\n",
    "        model=\"llama-3.3-70b-versatile\",  # Use a model optimized for summarization\n",
    "        temperature=0.5,\n",
    "        max_completion_tokens=512,\n",
    "        top_p=1,\n",
    "        stop=None,\n",
    "        stream=False,\n",
    "    )\n",
    "\n",
    "    return chat_completion.choices[0].message.content"
   ],
   "id": "a895b8529374c9cc",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T03:23:27.671193Z",
     "start_time": "2025-03-21T03:23:27.663585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def classify_bias(text):\n",
    "#     \"\"\"Classify bias using Groq API.\"\"\"\n",
    "#     chat_completion = client.chat.completions.create(\n",
    "#         messages=[\n",
    "#             {\"role\": \"system\", \"content\": \"You are an AI assistant trained to classify biases in text.\"},\n",
    "#             {\"role\": \"user\", \"content\": f\"\"\"\n",
    "#                 Classify the biases judgment under one of the following criteria:\n",
    "#                 A. Low risk of bias\n",
    "#                 B. Unclear risk of bias\n",
    "#                 C. High risk of bias\n",
    "#\n",
    "#                 In addition, provide a 'support for judgement' for any class (A, B, or C) chosen.\n",
    "#\n",
    "#                 Focus specifically on:\n",
    "#                 1. Random sequence generation (selection bias)\n",
    "#                 2. Allocation concealment (selection bias)\n",
    "#                 3. Blinding of participants and personnel (performance bias)\n",
    "#                 4. Blinding of outcome assessment (detection bias)\n",
    "#                 5. Incomplete outcome data (attrition bias)\n",
    "#                 6. Selective reporting (reporting bias)\n",
    "#                 7. Other bias\n",
    "#\n",
    "#                 Text:\n",
    "#                 {text}\n",
    "#\n",
    "#                 Respond in JSON format for each of the above (1,2,3,4,5,6,7):\n",
    "#                 {{\n",
    "#                     \"classification\": \"<Low/Unclear/High> risk of bias\",\n",
    "#                     \"support\": \"<justification>\"\n",
    "#                 }}\n",
    "#             \"\"\"}\n",
    "#         ],\n",
    "#         model=\"deepseek-r1-distill-qwen-32b\",\n",
    "#         temperature=0.5,\n",
    "#         max_completion_tokens=512,  # Reduce to prevent token limit errors\n",
    "#         top_p=1,\n",
    "#         stop=None,\n",
    "#         stream=False,\n",
    "#     )\n",
    "#\n",
    "#     return chat_completion.choices[0].message.content"
   ],
   "id": "cdc96da6e99476ac",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T03:24:57.142463Z",
     "start_time": "2025-03-21T03:23:29.902098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%capture cap1\n",
    "# # Main Execution\n",
    "# if __name__ == \"__main__\":\n",
    "#     pdf_path = \"01_NEJMoa2034577.pdf\"  # Change to your actual PDF path\n",
    "#     text = extract_text_from_pdf(pdf_path)\n",
    "#\n",
    "#     chunks = split_text(text)  # Split into smaller chunks\n",
    "#     summarized_chunks = [summarize_text(chunk) for chunk in chunks]  # Summarize each chunk\n",
    "#     results = []\n",
    "#\n",
    "#     for idx, chunk in enumerate(summarized_chunks):\n",
    "#         print(f\"Processing chunk {idx + 1}/{len(summarized_chunks)}...\")\n",
    "#         result = classify_bias(chunk)\n",
    "#         results.append(result)\n",
    "#\n",
    "#     print(\"\\nBias Classification Results:\")\n",
    "#     for res in results:\n",
    "#         print(res)\n",
    "#\n",
    "# # Save the captured output to a text file\n",
    "# with open('output1-NEJMoa2034577.txt', 'w') as file:\n",
    "#     file.write(cap1.stdout)"
   ],
   "id": "8d6bae338a1a2875",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Fix Biases",
   "id": "767d4b68620f1599"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T05:00:02.131996Z",
     "start_time": "2025-03-21T04:43:01.745681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%capture cap1\n",
    "#\n",
    "# import json\n",
    "# import re\n",
    "# from groq import Groq\n",
    "# import fitz  # PyMuPDF\n",
    "#\n",
    "# # Initialize Groq API Client\n",
    "# # client = Groq(api_key=\"your_groq_api_key\")\n",
    "#\n",
    "# BIAS_TYPES = [\n",
    "#     \"Random sequence generation (selection bias)\",\n",
    "#     \"Allocation concealment (selection bias)\",\n",
    "#     \"Blinding of participants and personnel (performance bias)\",\n",
    "#     \"Blinding of outcome assessment (detection bias)\",\n",
    "#     \"Incomplete outcome data (attrition bias)\",\n",
    "#     \"Selective reporting (reporting bias)\",\n",
    "#     \"Other bias\"\n",
    "# ]\n",
    "#\n",
    "# def extract_text_from_pdf(pdf_path):\n",
    "#     \"\"\"Extract text from a given PDF file.\"\"\"\n",
    "#     doc = fitz.open(pdf_path)\n",
    "#     text = \"\\n\".join([page.get_text(\"text\") for page in doc])\n",
    "#     return text\n",
    "#\n",
    "# def split_text(text, max_tokens=2000):\n",
    "#     \"\"\"Splits text into smaller chunks to fit within token limits.\"\"\"\n",
    "#     words = text.split()\n",
    "#     chunks = []\n",
    "#     chunk = []\n",
    "#\n",
    "#     for word in words:\n",
    "#         chunk.append(word)\n",
    "#         if len(chunk) >= max_tokens:\n",
    "#             chunks.append(\" \".join(chunk))\n",
    "#             chunk = []\n",
    "#\n",
    "#     if chunk:\n",
    "#         chunks.append(\" \".join(chunk))\n",
    "#\n",
    "#     return chunks\n",
    "#\n",
    "# def extract_json_from_text(response_text):\n",
    "#     \"\"\"Extract JSON content from the response using regex.\"\"\"\n",
    "#     match = re.search(r\"\\{.*\\}\", response_text, re.DOTALL)\n",
    "#     if match:\n",
    "#         return match.group(0)  # Return only the JSON part\n",
    "#     return None  # No valid JSON found\n",
    "#\n",
    "# def classify_bias(text):\n",
    "#     \"\"\"Classify bias for all 7 categories using Groq API.\"\"\"\n",
    "#\n",
    "#     bias_results = {}\n",
    "#\n",
    "#     for bias_type in BIAS_TYPES:\n",
    "#         chat_completion = client.chat.completions.create(\n",
    "#             messages=[\n",
    "#                 {\"role\": \"system\", \"content\": \"You are an AI assistant trained to classify biases in text.\"},\n",
    "#                 {\"role\": \"user\", \"content\": f\"\"\"\n",
    "#                     Analyze the following text and classify the bias under one of the following categories:\n",
    "#                     A. Low risk of bias\n",
    "#                     B. Unclear risk of bias\n",
    "#                     C. High risk of bias\n",
    "#\n",
    "#                     In addition, provide a 'support for judgement' explaining your classification.\n",
    "#\n",
    "#                     Focus specifically on: {bias_type}\n",
    "#\n",
    "#                     Text:\n",
    "#                     {text}\n",
    "#\n",
    "#                     Respond in JSON format:\n",
    "#                     {{\n",
    "#                         \"classification\": \"<Low/Unclear/High> risk of bias\",\n",
    "#                         \"support\": \"<justification>\"\n",
    "#                     }}\n",
    "#                 \"\"\"}\n",
    "#             ],\n",
    "#             model=\"deepseek-r1-distill-qwen-32b\",\n",
    "#             temperature=0.5,\n",
    "#             max_completion_tokens=512,\n",
    "#             top_p=1,\n",
    "#             stop=None,\n",
    "#             stream=False,\n",
    "#         )\n",
    "#\n",
    "#         response_text = chat_completion.choices[0].message.content\n",
    "#\n",
    "#         try:\n",
    "#             json_text = extract_json_from_text(response_text)  # Extract only JSON part\n",
    "#             if json_text:\n",
    "#                 response_json = json.loads(json_text)\n",
    "#                 bias_results[bias_type] = response_json\n",
    "#             else:\n",
    "#                 bias_results[bias_type] = {\"error\": \"Invalid JSON format returned\"}\n",
    "#\n",
    "#         except json.JSONDecodeError:\n",
    "#             bias_results[bias_type] = {\"error\": \"Failed to parse JSON response\"}\n",
    "#\n",
    "#     return bias_results\n",
    "#\n",
    "#\n",
    "# # Main Execution\n",
    "# if __name__ == \"__main__\":\n",
    "#     pdf_path = \"01_NEJMoa2034577.pdf\"  # Change to your actual PDF path\n",
    "#     text = extract_text_from_pdf(pdf_path)\n",
    "#\n",
    "#     chunks = split_text(text)  # Split into smaller chunks\n",
    "#     all_results = {}\n",
    "#\n",
    "#     for idx, chunk in enumerate(chunks):\n",
    "#         print(f\"Processing chunk {idx + 1}/{len(chunks)}...\")\n",
    "#         bias_results = classify_bias(chunk)\n",
    "#\n",
    "#         # Merge results from multiple chunks\n",
    "#         for key, value in bias_results.items():\n",
    "#             if key not in all_results:\n",
    "#                 all_results[key] = []\n",
    "#             all_results[key].append(value)\n",
    "#\n",
    "#     print(\"\\nFinal Bias Classification Results:\")\n",
    "#     print(json.dumps(all_results, indent=4))\n",
    "#\n",
    "# with open('01_NEJMoa2034577.txt', 'w') as file:\n",
    "#     file.write(cap1.stdout)"
   ],
   "id": "963b6588cfba6255",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Save to txt",
   "id": "54ddf9353f104466"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T00:58:07.421310Z",
     "start_time": "2025-03-25T00:58:07.313661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import re\n",
    "from groq import Groq\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Initialize Groq API Client\n",
    "# client = Groq(api_key=\"xxx\")\n",
    "\n",
    "BIAS_TYPES = [\n",
    "    \"Random sequence generation (selection bias)\",\n",
    "    \"Allocation concealment (selection bias)\",\n",
    "    \"Blinding of participants and personnel (performance bias)\",\n",
    "    \"Blinding of outcome assessment (detection bias)\",\n",
    "    \"Incomplete outcome data (attrition bias)\",\n",
    "    \"Selective reporting (reporting bias)\",\n",
    "    \"Other bias\"\n",
    "]\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a given PDF file.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\\n\".join([page.get_text(\"text\") for page in doc])\n",
    "    return text\n",
    "\n",
    "def split_text(text, max_tokens=2000):\n",
    "    \"\"\"Splits text into smaller chunks to fit within token limits.\"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    chunk = []\n",
    "\n",
    "    for word in words:\n",
    "        chunk.append(word)\n",
    "        if len(chunk) >= max_tokens:\n",
    "            chunks.append(\" \".join(chunk))\n",
    "            chunk = []\n",
    "\n",
    "    if chunk:\n",
    "        chunks.append(\" \".join(chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def extract_json_from_text(response_text):\n",
    "    \"\"\"Extract JSON content from the response using regex.\"\"\"\n",
    "    match = re.search(r\"\\{.*\\}\", response_text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(0)  # Return only the JSON part\n",
    "    return None  # No valid JSON found\n",
    "\n",
    "def classify_bias(text):\n",
    "    \"\"\"Classify bias for all 7 categories using Groq API.\"\"\"\n",
    "\n",
    "    bias_results = {}\n",
    "\n",
    "    for bias_type in BIAS_TYPES:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant trained to classify biases in text.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"\"\"\n",
    "                    Analyze the following text and classify the bias under one of the following categories:\n",
    "                    A. Low risk of bias\n",
    "                    B. Unclear risk of bias\n",
    "                    C. High risk of bias\n",
    "\n",
    "                    In addition, provide a 'support for judgement' explaining your classification.\n",
    "\n",
    "                    Focus specifically on: {bias_type}\n",
    "\n",
    "                    Text:\n",
    "                    {text}\n",
    "\n",
    "                    Respond in JSON format:\n",
    "                    {{\n",
    "                        \"classification\": \"<Low/Unclear/High> risk of bias\",\n",
    "                        \"support\": \"<justification>\"\n",
    "                    }}\n",
    "                \"\"\"}\n",
    "            ],\n",
    "            model=\"deepseek-r1-distill-qwen-32b\",\n",
    "            temperature=0.5,\n",
    "            max_completion_tokens=512,\n",
    "            top_p=1,\n",
    "            stop=None,\n",
    "            stream=False,\n",
    "        )\n",
    "\n",
    "        response_text = chat_completion.choices[0].message.content\n",
    "\n",
    "        try:\n",
    "            json_text = extract_json_from_text(response_text)  # Extract only JSON part\n",
    "            if json_text:\n",
    "                response_json = json.loads(json_text)\n",
    "                bias_results[bias_type] = response_json\n",
    "            else:\n",
    "                bias_results[bias_type] = {\"error\": \"Invalid JSON format returned\"}\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            bias_results[bias_type] = {\"error\": \"Failed to parse JSON response\"}\n",
    "\n",
    "    return bias_results\n",
    "\n",
    "\n",
    "def save_results_to_txt(results, output_file=\"./output/01_PIIS2666776221002465_bias_classification_results.txt\"):\n",
    "    \"\"\"Save classification results to a text file.\"\"\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(\"Bias Classification Results\\n\")\n",
    "        file.write(\"=\" * 50 + \"\\n\\n\")\n",
    "\n",
    "        for bias_type, assessments in results.items():\n",
    "            file.write(f\"{bias_type}:\\n\")\n",
    "            for assessment in assessments:\n",
    "                file.write(f\"  Classification: {assessment.get('classification', 'N/A')}\\n\")\n",
    "                file.write(f\"  Support: {assessment.get('support', 'N/A')}\\n\")\n",
    "                file.write(\"\\n\")\n",
    "\n",
    "        print(f\"\\nResults saved to {output_file}\")"
   ],
   "id": "611368de5ad9df9",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T01:12:05.889887Z",
     "start_time": "2025-03-25T00:58:24.911518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = \"./articles/01_PIIS2666776221002465.pdf\"  # PDF path\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    chunks = split_text(text)  # Split into smaller chunks\n",
    "    all_results = {}\n",
    "\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        print(f\"Processing chunk {idx + 1}/{len(chunks)}...\")\n",
    "        bias_results = classify_bias(chunk)\n",
    "\n",
    "        # Merge results from multiple chunks\n",
    "        for key, value in bias_results.items():\n",
    "            if key not in all_results:\n",
    "                all_results[key] = []\n",
    "            all_results[key].append(value)\n",
    "\n",
    "    # Save to text file\n",
    "    save_results_to_txt(all_results)"
   ],
   "id": "d707a713754affe5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1/4...\n",
      "Processing chunk 2/4...\n",
      "Processing chunk 3/4...\n",
      "Processing chunk 4/4...\n",
      "\n",
      "Results saved to ./output/01_PIIS2666776221002465_bias_classification_results.txt\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
